{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "sd_traffic = pd.read_csv(\"../Hackathon Datasets/Traffic/sd_traffic_2015_locations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will be exploring the US Traffic 2015 dataset for San Diego. The dataset was taken from the US department of Transportation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24182, 41)\n"
     ]
    }
   ],
   "source": [
    "print(sd_traffic.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of data. Below will have additional inofmration regarding the type of data to better describe the graphs. Some information could not be found which will be highlighted in italics\n",
    "\n",
    "San Diego Traffic dataset (191057x39 dataframe)\n",
    "    * date\n",
    "    * day_of_data\n",
    "    * day_of_week\n",
    "    * fips_state_code: Federal Information Processing Standards. 06 assigned to California\n",
    "    * <i>lane_of_travel</i>\n",
    "    * month_of_data\n",
    "    * <i>record_type</i>\n",
    "    * restrictions: All data is NaN\n",
    "    * <i>station_id</i>\n",
    "    * traffic_volume_counted_after_.... - Traffic volume by bins \n",
    "    * year_of_data: Year the data was taken \n",
    "    * Direction of Travel:\n",
    "        1 - North\n",
    "        3- East\n",
    "        5 - South\n",
    "        7 - West\n",
    "    * Functional Classification: Symbol\n",
    "    * Functional Classification Name: Type of road (urban: principal arterial - interstate)\n",
    "    * Latitude\n",
    "    * Longitude\n",
    "\n",
    "San Diego Traffic Station dataset (52x56 dataframe)\n",
    "    * algorithm_of_vehicle_classification: All values are NaN\n",
    "    * algorithm_of_vehicle_classification_name: All values are NaN\n",
    "    * calibration_of_weighing_system\n",
    "    * calibration_of_weighing_system_name\n",
    "    * classification_system_for_vehicle_classification\n",
    "    * concurrent_route_signing\n",
    "    * concurrent_signed_route_number\n",
    "    * concurrent_signed_route_number\n",
    "    * direction_of_travel_name\n",
    "    * fips_county_code\n",
    "    * fips_state_code\n",
    "    * functional_classification\n",
    "    * functional_classification_name\n",
    "    * hpms_sample_identifies: Values are NaN\n",
    "    * hpms_sample_type: Values are NaN\n",
    "    * lane_of_travel: 0, 1, 2, 3, 4, 5, 7\n",
    "    * lane_of_travel_name:\n",
    "        * 0 - data with lanes combined\n",
    "        * 1 - Outside (rightmost) lane\n",
    "        * 2 - Other lanes\n",
    "        * 3 - Other lanes\n",
    "        * 4 - Other lanes\n",
    "        * 5 - Other lanes\n",
    "        * 7 - Other lanes\n",
    "    * latitude\n",
    "    * longitude \n",
    "    * lrs_identification\n",
    "    * lrs_location_point\n",
    "    * method_of_data_retrieval\n",
    "    * method_of_data_retrieval_name\n",
    "    * method_of_traffic_volume_counting\n",
    "    * method_of_traffic_volume_counting_name\n",
    "    * method_of_truck_weighing \n",
    "    * method_of_truck_weighing_name\n",
    "    * method_of_vehicle_classification \n",
    "    * method_of_vehicle_classification_name\n",
    "    * national_highway_system \n",
    "    * number_of_lanes_in_direction_indicated \n",
    "    * number_of_lanes_monitored_for_traffic_volume \n",
    "    * number_of_lanes_monitored_for_truck_weight \n",
    "    * number_of_lanes_monitored_for_vehicle_class\n",
    "    * posted_route_signing \n",
    "    * posted_signed_route_number\n",
    "    * previous_station_idprimary_purpose \n",
    "    * primary_purpose_namerecord_type\n",
    "    * sample_type_for_traffic_volume \n",
    "    * sample_type_for_traffic_volume_name\n",
    "    * sample_type_for_truck_weight \n",
    "    * sample_type_for_truck_weight_name \n",
    "    * sample_type_for_vehicle_classification \n",
    "    * sample_type_for_vehicle_classification_name\n",
    "    * second_type_of_sensor \n",
    "    * shrp_site_identificationstation_id\n",
    "    * station_location \n",
    "    * type_of_sensortype_of_sensor_name\n",
    "    * year_of_data \n",
    "    * year_station_discontinued\n",
    "    * year_station_established\n",
    "  \n",
    "We will drop the following columns from the sdt dataset, as of right now we only care about traffic density and not direction of traffic. After this sdt will have 33 columns\n",
    "    * fips_state_code, lane_of_travel, record_type, restrictions, functional_classification,\n",
    "    functional_classification_name\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "_uuid": "83dccd290af0be7a3f72d9f1cc0329f3db186867"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24182, 35)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_traffic_drop_columns = [\"fips_state_code\",\"lane_of_travel\",\"record_type\",\"restrictions\", \\\n",
    "                   \"functional_classification\",\"functional_classification_name\"]\n",
    "sd_traffic_ds = sd_traffic.drop(sd_traffic_drop_columns, axis=1)\n",
    "sd_traffic_ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now begin to look at the data to find different type of traffic patterns.\n",
    "\n",
    "We have three station ids in the data set which correspond to three separate locations\n",
    "    119030 (intersection of 5 and 15) -> 32.692872  117.121745 (8304 rows)\n",
    "    119100 (crossover of 15 and 805 near parque linda) -> 32.732428  117.111704 (8688 rows)\n",
    "    119740 (94 near Golden Hill) -> 32.713208  117.133743 (7190 rows)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119030\n",
      "    latitude   longitude\n",
      "0  32.692872  117.121745\n",
      "119100\n",
      "       latitude   longitude\n",
      "8304  32.732428  117.111704\n",
      "119740\n",
      "        latitude   longitude\n",
      "16992  32.713208  117.133743\n"
     ]
    }
   ],
   "source": [
    "\n",
    "station_ids = sd_traffic_ds[\"station_id\"].unique()\n",
    "for i in station_ids:\n",
    "    print(Stationi)\n",
    "    print(sd_traffic_ds[sd_traffic_ds[\"station_id\"] == i][[\"latitude\",\"longitude\"]].head(1))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
